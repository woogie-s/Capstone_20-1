{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.tag import Komoran\n",
    "from konlpy.tag import Hannanum\n",
    "#from konlpy.tag import Mecab\n",
    "import MeCab\n",
    "from konlpy.tag import Okt\n",
    "import re\n",
    "import nltk\n",
    "import gensim\n",
    "# í˜•íƒœì†Œ ë¶„ì„ì„ ìœ„í•œ ê°ì²´ ìƒì„±.\n",
    "kkma = Kkma()\n",
    "komoran = Komoran()\n",
    "hannanum = Hannanum()\n",
    "mecab = MeCab.Tagger()\n",
    "#mecab = Mecab()\n",
    "okt = Okt()\n",
    "from openpyxl import Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('C:/capstone/review/238343_trainReviews.csv',usecols = ['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mecab_nouns(text):\n",
    "    nouns = []\n",
    "    \n",
    "   \n",
    "    pattern = re.compile(\".*\\t[A-Z]+\") \n",
    "    \n",
    "    temp = [tuple(pattern.match(token).group(0).split(\"\\t\")) for token in mecab.parse(text).splitlines()[:-1]]\n",
    "        \n",
    "    for token in temp:\n",
    "        if token[1] == \"NNG\" or token[1] == \"NNP\" or token[1] == \"NNB\" or token[1] == \"NNBC\" or token[1] == \"NP\" or token[1] == \"NR\":\n",
    "            nouns.append(token[0])\n",
    "        \n",
    "    return nouns\n",
    "\n",
    "def mecab_morphs(text):\n",
    "    morphs = []\n",
    "    \n",
    "    pattern = re.compile(\".*\\t[A-Z]+\") \n",
    "    \n",
    "    temp = [tuple(pattern.match(token).group(0).split(\"\\t\")) for token in mecab.parse(text).splitlines()[:-1]]\n",
    "        \n",
    "    for token in temp:\n",
    "        morphs.append(token[0])\n",
    "    \n",
    "    return morphs\n",
    "\n",
    "def mecab_pos(text):\n",
    "    pos = []\n",
    "    pattern = re.compile(\".*\\t[A-Z]+\") \n",
    "    \n",
    "    pos = [tuple(pattern.match(token).group(0).split(\"\\t\")) for token in mecab.parse(text).splitlines()[:-1]]\n",
    "        \n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(doc):\n",
    "    doc = re.sub(\"[^ã„±-ã…ã…-ã…£ê°€-í£ ]\", \"\", str(doc))\n",
    "    return doc\n",
    "\n",
    "def define_stopwords(path):\n",
    "    \n",
    "    SW = set()\n",
    "    \n",
    "    with open(path) as f:\n",
    "        for word in f:\n",
    "            SW.add(word)\n",
    "            \n",
    "    return SW\n",
    "\n",
    "def text_tokenizing(doc):\n",
    "    \n",
    "    \n",
    "    return [word for word in mecab_morphs(doc) if word not in SW and len(word) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp ='C:/capstone/stopwords-ko.txt'\n",
    "SW = define_stopwords(rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences = reviews['content'].apply(text_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = sentences.apply(text_tokenizing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         ê´‘ê³  ë„ˆë¬´ ë§ì´ ë‚˜ì˜¤ ë„ˆë¬´ ì§œì¦ ë‚˜ìš” ê·¸ë¦¬ê³  ë§Œë“  ì§€ë§Œ ê·¸ë ˆ ê´‘êµ¬ ë„ˆë¬´ ë§ì´ ë‚˜ì™€ ...\n",
       "1         í¼ì¦ ê²Œì„ ìœ¼ë‚˜ í¼ì¦ ì»¨íŠ¸ë¡¤ ë„ˆë¬´ ë©‹ëŒ€ë¡œ ì´ë™ ë¶ˆê°€ ë³´ë‹¤ í¼ì¦ ì°¨ì„œ í¼í™íŠ¸ ì–´ë µ ì™„...\n",
       "2                  ë‘ë‡Œ ë§ì´ ê²Œì„ ì¬ë¯¸ ë˜í•œ ë›°ì–´ë‚˜ ì‹œì‘ ëª»í•˜ ë‹¨ì  ê·¸ë˜ë„ ì‹œê°„ ë³´ë‚´ ë„¤ìš”\n",
       "3         ì§„ì§œ ì•„ìš” ë‹¤ë¥¸ ì´ëŸ° ê²Œì„ ê±°ë“ ìš” ê·¼ë° ì´ê±¸ ê¸ˆë°© ì§€ë‚˜ ë‹¤ë¥¸ ì§€ë‚˜ ê±°ë“ ìš” ê·¼ë° ì´ê±°...\n",
       "4                ì‹œê°„ ì œí•œ ê´‘ê³  ê³¼í•˜ ì¡°ì•„ ë§Œë“œì…¨ ì–´ìš” ì •ì  ì„±í–¥ ì‚¬ëŒ ì—ê²Œ ì •ë§ ê²Œì„ ì˜ˆìš”\n",
       "                                ...                        \n",
       "238338                                      ë°˜ìª½ ì€ë° ê·¸ë¦¬ê³  ë²„ê·¸ í˜ì¹˜\n",
       "238339                                             ì¡°ì§€ ê±¸ë¦¬ ì‹¤í–‰\n",
       "238340                                                ë§¤ë²ˆ ê´‘ê³ \n",
       "238341                                                     \n",
       "238342                                                  ì˜¤ì„¸ë¯¼\n",
       "Name: content, Length: 238343, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.apply(text_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148067\n"
     ]
    }
   ],
   "source": [
    "tokens_len = 0\n",
    "for i in range(len(tokens)):\n",
    "    if len(tokens[i])>5:\n",
    "        tokens_len = tokens_len +1\n",
    "        \n",
    "print(tokens_len)\n",
    "for i in range(len(tokens)):\n",
    "    if len(tokens[i])>5:\n",
    "        tokens_len = tokens_len +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(tokens, size=100, window = 2, min_count=30, workers=4, iter=100, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Word2Vec.model'\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5236"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-a5b307f48e61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'vocab' is not defined"
     ]
    }
   ],
   "source": [
    "sorted(vocab, key=vocab.get, reverse=True)[150:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5236"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list = list(vocab)[:]\n",
    "len(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ì–´ë µ', 0.6476881504058838),\n",
       " ('ì–´ë ¤ì›Œìš”', 0.6009589433670044),\n",
       " ('ì–´ë ¤ì›Œ', 0.5819164514541626),\n",
       " ('ì–´ë ¤', 0.5375822186470032),\n",
       " ('ì–´ë ¤ì›Œì„œ', 0.536943793296814),\n",
       " ('í˜ë“­ë‹ˆë‹¤', 0.5282131433486938),\n",
       " ('ì‰¬ì›€', 0.5242308378219604),\n",
       " ('í˜ë“¤', 0.5234535932540894),\n",
       " ('ì‰¬ì› ', 0.5225168466567993),\n",
       " ('ì‰¬ì›Œ', 0.5129581689834595)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('ì–´ë ¤ì›€')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_length = len(vocab_list)\n",
    "word_metrix = np.zeros((vocab_length,100))\n",
    "\n",
    "#word_metrix = [model.wv.get_vector(v) for v in model.wv.vocab.keys()] \n",
    "#ë‹¨ì–´í–‰ë ¬\n",
    "for i in range(vocab_length):\n",
    "        word_metrix[i] = model.wv.get_vector(vocab_list[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ê±°ë¦¬ í–‰ë ¬ê³¼ ê°€ì¤‘ì¹˜ í–‰ë ¬(ì •ê·œë¶„í¬ ì ìš©, ì •ê·œë¶„í¬ì— ê°€ê¹Œì›Œì§€ë„ë¡ í•˜ëŠ” ë¶„ì‚° ê°’ í™•ì¸ í•„ìš”) \n",
    "distance_matrix = euclidean_distances(word_metrix, word_metrix)\n",
    "weight_matrix = np.exp(-(distance_matrix ** 2) / (2 * np.var(distance_matrix)))\n",
    "\n",
    "#print(distance_matrix)\n",
    "#print(weight_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1250\n",
      "2739\n",
      "1774\n",
      "992\n",
      "1448\n",
      "1776\n",
      "2874\n",
      "2748\n",
      "1461\n",
      "1710\n",
      "640\n",
      "791\n",
      "1446\n",
      "1078\n",
      "1137\n",
      "1282\n",
      "1120\n",
      "1264\n",
      "1251\n",
      "228\n",
      "2783\n",
      "1407\n",
      "303\n",
      "245\n",
      "1352\n",
      "1411\n",
      "1323\n",
      "1445\n",
      "547\n",
      "663\n",
      "776\n",
      "3734\n",
      "276\n",
      "714\n",
      "486\n"
     ]
    }
   ],
   "source": [
    "print(vocab_list.index('ê´‘ê³ '))\n",
    "\n",
    "print(vocab_list.index('ê²°ì œ'))\n",
    "\n",
    "print(vocab_list.index('ì¶©ì „'))\n",
    "print(vocab_list.index('êµ¬ë§¤'))\n",
    "print(vocab_list.index('í˜„ì§ˆ'))\n",
    "print(vocab_list.index('í™˜ë¶ˆ'))\n",
    "\n",
    "print(vocab_list.index('ê³„ì •'))\n",
    "\n",
    "print(vocab_list.index('ì•„ì´ë””'))\n",
    "print(vocab_list.index('ì—°ë™'))\n",
    "print(vocab_list.index('ë¡œê·¸ì¸'))\n",
    "print(vocab_list.index('ê°€ì…'))\n",
    "\n",
    "\n",
    "print(vocab_list.index('ì„œë²„'))\n",
    "\n",
    "print(vocab_list.index('ì—°ê²°'))\n",
    "print(vocab_list.index('ì ‘ì†'))\n",
    "print(vocab_list.index('ë¡œë”©'))\n",
    "print(vocab_list.index('ì™€ì´íŒŒì´'))\n",
    "\n",
    "print(vocab_list.index('êµ¬ì„±'))\n",
    "\n",
    "print(vocab_list.index('ì´ë²¤íŠ¸'))\n",
    "print(vocab_list.index('í€˜ìŠ¤íŠ¸'))\n",
    "print(vocab_list.index('ìŠ¤í…Œì´ì§€'))\n",
    "print(vocab_list.index('ì–´ë ¤ìš´'))\n",
    "\n",
    "#print(vocab_list.index('ì—°ì¶œ'))\n",
    "print(vocab_list.index('ëª¨ì…˜'))\n",
    "print(vocab_list.index('ë°°ê²½'))\n",
    "print(vocab_list.index('ê·¸ë˜í”½'))\n",
    "print(vocab_list.index('ì†Œë¦¬'))\n",
    "print(vocab_list.index('ë””ìì¸'))\n",
    "\n",
    "print(vocab_list.index('ìºë¦­'))\n",
    "\n",
    "print(vocab_list.index('ìŠ¤í‚¬'))\n",
    "print(vocab_list.index('ì˜ì›…'))\n",
    "print(vocab_list.index('ì•„ì´í…œ'))\n",
    "print(vocab_list.index('ìŠ¤í‚¨'))\n",
    "\n",
    "#print(vocab_list.index('ì‹œìŠ¤í…œ'))\n",
    "print(vocab_list.index('ì—…ë°ì´íŠ¸'))\n",
    "print(vocab_list.index('ìš©ëŸ‰'))\n",
    "print(vocab_list.index('ë‹¤ìš´'))\n",
    "print(vocab_list.index('ë²„ê·¸'))\n",
    "print(vocab_list.index('ì„¤ì¹˜'))\n",
    "\n",
    "\n",
    "\n",
    "a0 = weight_matrix[0]#ê´‘ê³ \n",
    "\n",
    "a1 = weight_matrix[1250]#ê²°ì œ\n",
    "a2 = weight_matrix[2739]#ì¶©ì „\n",
    "a3 = weight_matrix[1774]#êµ¬ë§¤\n",
    "a4 = weight_matrix[992]#í˜„ì§ˆ\n",
    "a5 = weight_matrix[1448]#í™˜ë¶ˆ\n",
    "\n",
    "a6 = weight_matrix[1776]#ê³„ì •\n",
    "a7 = weight_matrix[2874]#ì•„ì´ë””\n",
    "a8 = weight_matrix[2748]#ì—°ë™\n",
    "a9 = weight_matrix[1461]#ë¡œê·¸ì¸\n",
    "a10 = weight_matrix[1710]#ê°€ì…\n",
    "\n",
    "a11 = weight_matrix[640]#ì„œë²„\n",
    "a12 = weight_matrix[791]#ì—°ê²°\n",
    "a13 = weight_matrix[1446]#ì ‘ì†\n",
    "a14 = weight_matrix[1078]#ë¡œë”©\n",
    "a15 = weight_matrix[1137]#ì™€ì´íŒŒì´\n",
    "\n",
    "a16 = weight_matrix[1282]#êµ¬ì„±\n",
    "a17 = weight_matrix[1120]#ì´ë²¤íŠ¸\n",
    "a18 = weight_matrix[1264]#í€˜ìŠ¤íŠ¸\n",
    "a19 = weight_matrix[1251]#ìŠ¤í…Œì´ì§€\n",
    "a20 = weight_matrix[228]#ì–´ë ¤ìš´\n",
    "\n",
    "a21 = weight_matrix[2783]#íš¨ê³¼\n",
    "a22 = weight_matrix[1407]#ë°°ê²½\n",
    "a23 = weight_matrix[303]#ê·¸ë˜í”½\n",
    "a24 = weight_matrix[245]#ì†Œë¦¬\n",
    "a25 = weight_matrix[1352]#ë””ìì¸\n",
    "\n",
    "a26 = weight_matrix[1411]#ìºë¦­í„°\n",
    "a27 = weight_matrix[1323]#ìŠ¤í‚¬\n",
    "a28 = weight_matrix[1445]#ì˜ì›…\n",
    "a29 = weight_matrix[547]#ì•„ì´í…œ\n",
    "a30 = weight_matrix[663]#ìŠ¤í‚¨\n",
    "\n",
    "a31 = weight_matrix[776]#ì—…ë°ì´íŠ¸\n",
    "a32 = weight_matrix[3734]#ìš©ëŸ‰\n",
    "a33 = weight_matrix[276]#ë‹¤ìš´\n",
    "a34 = weight_matrix[714]#ë²„ê·¸\n",
    "a35 = weight_matrix[486]#ì„¤ì¹˜\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_M=np.array([a0,a1,a2,a3,a4,a5,a6,a7,a8,a9,a10,a11,a12,a13,a14,a15,a16,a17,a18,a19,a20,a21,a22,a23,a24,a25,a26,a27,a28,a29,a30,a31,a32,a33,a34,a35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TDM ì„¤ê³„\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ìš°ë¦¬ê°€ ìƒˆë¡œ ë„£ì–´ì„œ ë¶„ì„í•  ë¦¬ë·°ë“¤\n",
    "train_reviews = pd.read_csv('C:/capstone/review/238343_trainReviews.csv')\n",
    "sentences = train_reviews['content'].apply(text_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CountVectorizer \n",
    "vectorizer = CountVectorizer(tokenizer = text_tokenizing ,vocabulary= vocab_list, binary= bool)\n",
    "#print(vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = vectorizer.fit_transform(sentences)\n",
    "#print(X2.toarray().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ë‚´ì ì„ ìœ„í•´ íŠ¸ëœìŠ¤í¼\n",
    "term_document_matrix = X2.toarray().T\n",
    "#print(X3)\n",
    "#print(W_M.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì˜ˆì „ë¶€í„° ê¾¸ë¯¸ëŠ”ê±¸ ì¢‹ì•„í•˜ê¸°ë•Œë¬¸ì— ì´ëŸ° ê²Œì„ì€ êµ¿! íŠ¹íˆ ë‚´ë§˜ëŒ€ë¡œ ê°€êµ¬ë¥¼ ê¾¸ë¯¸ëŠ” ì§‘ê¾¸ë¯¸ê¸° ê²Œì„ì´ ë‚˜ì˜¤ë©´ í•˜ê³ ì‹¶ì—ˆë˜ ê·¸ëŸ° ê²Œì„ì´ë¼ ë” ì¢‹ë„¤ìš”^^'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rv = 6418\n",
    "sample_content = train_reviews['content'][rv]\n",
    "sample_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "function_score = np.dot(W_M , term_document_matrix[ : ,rv:rv+1])\n",
    "#sorted(function_score, reverse=True)#ë‚´ì "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  :  [0.10819491]\n",
      "1  :  [0.00283533]\n",
      "2  :  [0.00831699]\n",
      "3  :  [0.00813239]\n",
      "4  :  [0.04569306]\n",
      "5  :  [0.00040915]\n",
      "6  :  [0.00361461]\n",
      "7  :  [0.00386808]\n",
      "8  :  [0.00152125]\n",
      "9  :  [0.00510926]\n",
      "10  :  [0.00070622]\n",
      "11  :  [0.01618083]\n",
      "12  :  [0.00290327]\n",
      "13  :  [0.02882852]\n",
      "14  :  [0.01451631]\n",
      "15  :  [0.00386752]\n",
      "16  :  [0.02296548]\n",
      "17  :  [0.09038066]\n",
      "18  :  [0.02541966]\n",
      "19  :  [0.02858158]\n",
      "20  :  [0.01487076]\n",
      "21  :  [0.00165308]\n",
      "22  :  [0.01849224]\n",
      "23  :  [0.03489618]\n",
      "24  :  [0.03933616]\n",
      "25  :  [0.00803098]\n",
      "26  :  [0.05342604]\n",
      "27  :  [0.02028579]\n",
      "28  :  [0.02441009]\n",
      "29  :  [0.09485869]\n",
      "30  :  [0.02720481]\n",
      "31  :  [0.08082249]\n",
      "32  :  [0.00167413]\n",
      "33  :  [0.02102412]\n",
      "34  :  [0.07071483]\n",
      "35  :  [0.04706678]\n"
     ]
    }
   ],
   "source": [
    "for i in range(36):\n",
    "    print(i, \" : \", function_score[:][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#print(function_score)\n",
    "for i in range(36):\n",
    "    if function_score[i]==max(function_score):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ê·¸ ë¦¬ë·°ê°€ ì–´ëŠ ê¸°ëŠ¥ì— ì†í•˜ëŠ”ì§€\n",
    "arr1 = np.zeros(len(sentences))\n",
    "arr2 = np.zeros(len(sentences))\n",
    "arr3 = np.zeros(len(sentences))\n",
    "\n",
    "arr1.fill(50)\n",
    "arr2.fill(50)\n",
    "arr3.fill(50)\n",
    "\n",
    "score = 0.2\n",
    "for j in range(len(sentences)):\n",
    "    function_score = np.dot(W_M , term_document_matrix[ : ,j:j+1])\n",
    "    fs = sorted(function_score, reverse = True)\n",
    "    \n",
    "    if fs[0]>score:\n",
    "        if fs[0]==fs[1]:\n",
    "            arr1[j] = np.where(function_score==fs[0])[0][0]\n",
    "            arr2[j] = np.where(function_score==fs[0])[0][1]\n",
    "            if fs[2]>score:\n",
    "                arr3[j] = np.where(function_score==fs[2])[0]\n",
    "            continue\n",
    "        \n",
    "        arr1[j] = np.where(function_score==fs[0])[0]\n",
    "\n",
    "    \n",
    "    if fs[1]>score:\n",
    "        arr2[j] = np.where(function_score==fs[1])[0]\n",
    "    \n",
    "    \n",
    "    if fs[2]>score:\n",
    "        arr3[j] = np.where(function_score==fs[2])[0]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "category1 = list()\n",
    "for i in range(len(sentences)):\n",
    "    if arr1[i]==0:\n",
    "        category1.append('ê´‘ê³ ')\n",
    "    elif arr1[i]==1:\n",
    "        category1.append('ê²°ì œ')\n",
    "    elif arr1[i]==2:\n",
    "        category1.append('ì¶©ì „')\n",
    "    elif arr1[i]==3:\n",
    "        category1.append('êµ¬ë§¤')       \n",
    "    elif arr1[i]==4:\n",
    "        category1.append('í˜„ì§ˆ')       \n",
    "    elif arr1[i]==5:\n",
    "        category1.append('í™˜ë¶ˆ')\n",
    "    elif arr1[i]==6:\n",
    "        category1.append('ê³„ì •')\n",
    "    elif arr1[i]==7:\n",
    "        category1.append('ì•„ì´ë””')\n",
    "    elif arr1[i]==8:\n",
    "        category1.append('ì—°ë™')\n",
    "    elif arr1[i]==9:\n",
    "        category1.append('ë¡œê·¸ì¸')\n",
    "    elif arr1[i]==10:\n",
    "        category1.append('ê°€ì…')\n",
    "    elif arr1[i]==11:\n",
    "        category1.append('ì„œë²„')\n",
    "    elif arr1[i]==12:\n",
    "        category1.append('ì—°ê²°')\n",
    "    elif arr1[i]==13:\n",
    "        category1.append('ì ‘ì†')\n",
    "    elif arr1[i]==14:\n",
    "        category1.append('ë¡œë”©')\n",
    "    elif arr1[i]==15:\n",
    "        category1.append('ë„¤íŠ¸ì›Œí¬')\n",
    "    elif arr1[i]==16:\n",
    "        category1.append('êµ¬ì„±')\n",
    "    elif arr1[i]==17:\n",
    "        category1.append('ì´ë²¤íŠ¸')\n",
    "    elif arr1[i]==18:\n",
    "        category1.append('í€˜ìŠ¤íŠ¸')\n",
    "    elif arr1[i]==19:\n",
    "        category1.append('ìŠ¤í…Œì´ì§€')\n",
    "    elif arr1[i]==20:\n",
    "        category1.append('ë‚œì´ë„')\n",
    "    elif arr1[i]==21:\n",
    "        category1.append('ëª¨ì…˜')\n",
    "    elif arr1[i]==22:\n",
    "        category1.append('ë°°ê²½')\n",
    "    elif arr1[i]==23:\n",
    "        category1.append('ê·¸ë˜í”½')\n",
    "    elif arr1[i]==24:\n",
    "        category1.append('ì†Œë¦¬')\n",
    "    elif arr1[i]==25:\n",
    "        category1.append('ë””ìì¸')\n",
    "    elif arr1[i]==26:\n",
    "        category1.append('ìºë¦­í„°')\n",
    "    elif arr1[i]==27:\n",
    "        category1.append('ìŠ¤í‚¬')\n",
    "    elif arr1[i]==28:\n",
    "        category1.append('ì˜ì›…')\n",
    "    elif arr1[i]==29:\n",
    "        category1.append('ì•„ì´í…œ')\n",
    "    elif arr1[i]==30:\n",
    "        category1.append('ìŠ¤í‚¨')\n",
    "    elif arr1[i]==31:\n",
    "        category1.append('ì—…ë°ì´íŠ¸')\n",
    "    elif arr1[i]==32:\n",
    "        category1.append('ìš©ëŸ‰')\n",
    "    elif arr1[i]==33:\n",
    "        category1.append('ë‹¤ìš´')\n",
    "    elif arr1[i]==34:\n",
    "        category1.append('ë²„ê·¸')\n",
    "    elif arr1[i]==35:\n",
    "        category1.append('ì„¤ì¹˜')\n",
    "    elif arr1[i]==50:\n",
    "        category1.append('ê¸°íƒ€')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238343"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(category1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "category2 = list()\n",
    "for i in range(len(sentences)):\n",
    "    if arr2[i]==0:\n",
    "        category2.append('ê´‘ê³ ')\n",
    "    elif arr2[i]==1:\n",
    "        category2.append('ê²°ì œ')\n",
    "    elif arr2[i]==2:\n",
    "        category2.append('ì¶©ì „')\n",
    "    elif arr2[i]==3:\n",
    "        category2.append('êµ¬ë§¤')       \n",
    "    elif arr2[i]==4:\n",
    "        category2.append('í˜„ì§ˆ')       \n",
    "    elif arr2[i]==5:\n",
    "        category2.append('í™˜ë¶ˆ')\n",
    "    elif arr2[i]==6:\n",
    "        category2.append('ê³„ì •')\n",
    "    elif arr2[i]==7:\n",
    "        category2.append('ì•„ì´ë””')\n",
    "    elif arr2[i]==8:\n",
    "        category2.append('ì—°ë™')\n",
    "    elif arr2[i]==9:\n",
    "        category2.append('ë¡œê·¸ì¸')\n",
    "    elif arr2[i]==10:\n",
    "        category2.append('ê°€ì…')\n",
    "    elif arr2[i]==11:\n",
    "        category2.append('ì„œë²„')\n",
    "    elif arr2[i]==12:\n",
    "        category2.append('ì—°ê²°')\n",
    "    elif arr2[i]==13:\n",
    "        category2.append('ì ‘ì†')\n",
    "    elif arr2[i]==14:\n",
    "        category2.append('ë¡œë”©')\n",
    "    elif arr2[i]==15:\n",
    "        category2.append('ë„¤íŠ¸ì›Œí¬')\n",
    "    elif arr2[i]==16:\n",
    "        category2.append('êµ¬ì„±')\n",
    "    elif arr2[i]==17:\n",
    "        category2.append('ì´ë²¤íŠ¸')\n",
    "    elif arr2[i]==18:\n",
    "        category2.append('í€˜ìŠ¤íŠ¸')\n",
    "    elif arr2[i]==19:\n",
    "        category2.append('ìŠ¤í…Œì´ì§€')\n",
    "    elif arr2[i]==20:\n",
    "        category2.append('ë‚œì´ë„')\n",
    "    elif arr2[i]==21:\n",
    "        category2.append('ëª¨ì…˜')\n",
    "    elif arr2[i]==22:\n",
    "        category2.append('ë°°ê²½')\n",
    "    elif arr2[i]==23:\n",
    "        category2.append('ê·¸ë˜í”½')\n",
    "    elif arr2[i]==24:\n",
    "        category2.append('ì†Œë¦¬')\n",
    "    elif arr2[i]==25:\n",
    "        category2.append('ë””ìì¸')\n",
    "    elif arr2[i]==26:\n",
    "        category2.append('ìºë¦­í„°')\n",
    "    elif arr2[i]==27:\n",
    "        category2.append('ìŠ¤í‚¬')\n",
    "    elif arr2[i]==28:\n",
    "        category2.append('ì˜ì›…')\n",
    "    elif arr2[i]==29:\n",
    "        category2.append('ì•„ì´í…œ')\n",
    "    elif arr2[i]==30:\n",
    "        category2.append('ìŠ¤í‚¨')\n",
    "    elif arr2[i]==31:\n",
    "        category2.append('ì—…ë°ì´íŠ¸')\n",
    "    elif arr2[i]==32:\n",
    "        category2.append('ìš©ëŸ‰')\n",
    "    elif arr2[i]==33:\n",
    "        category2.append('ë‹¤ìš´')\n",
    "    elif arr2[i]==34:\n",
    "        category2.append('ë²„ê·¸')\n",
    "    elif arr2[i]==35:\n",
    "        category2.append('ì„¤ì¹˜')\n",
    "    elif arr3[i]==50:\n",
    "        category2.append('ê¸°íƒ€')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "category3 = list()\n",
    "for i in range(len(sentences)):\n",
    "    if arr3[i]==0:\n",
    "        category3.append('ê´‘ê³ ')\n",
    "    elif arr3[i]==1:\n",
    "        category3.append('ê²°ì œ')\n",
    "    elif arr3[i]==2:\n",
    "        category3.append('ì¶©ì „')\n",
    "    elif arr3[i]==3:\n",
    "        category3.append('êµ¬ë§¤')       \n",
    "    elif arr3[i]==4:\n",
    "        category3.append('í˜„ì§ˆ')       \n",
    "    elif arr3[i]==5:\n",
    "        category3.append('í™˜ë¶ˆ')\n",
    "    elif arr3[i]==6:\n",
    "        category3.append('ê³„ì •')\n",
    "    elif arr3[i]==7:\n",
    "        category3.append('ì•„ì´ë””')\n",
    "    elif arr3[i]==8:\n",
    "        category3.append('ì—°ë™')\n",
    "    elif arr3[i]==9:\n",
    "        category3.append('ë¡œê·¸ì¸')\n",
    "    elif arr3[i]==10:\n",
    "        category3.append('ê°€ì…')\n",
    "    elif arr3[i]==11:\n",
    "        category3.append('ì„œë²„')\n",
    "    elif arr3[i]==12:\n",
    "        category3.append('ì—°ê²°')\n",
    "    elif arr3[i]==13:\n",
    "        category3.append('ì ‘ì†')\n",
    "    elif arr3[i]==14:\n",
    "        category3.append('ë¡œë”©')\n",
    "    elif arr3[i]==15:\n",
    "        category3.append('ë„¤íŠ¸ì›Œí¬')\n",
    "    elif arr3[i]==16:\n",
    "        category3.append('êµ¬ì„±')\n",
    "    elif arr3[i]==17:\n",
    "        category3.append('ì´ë²¤íŠ¸')\n",
    "    elif arr3[i]==18:\n",
    "        category3.append('í€˜ìŠ¤íŠ¸')\n",
    "    elif arr3[i]==19:\n",
    "        category3.append('ìŠ¤í…Œì´ì§€')\n",
    "    elif arr3[i]==20:\n",
    "        category3.append('ë‚œì´ë„')\n",
    "    elif arr3[i]==21:\n",
    "        category3.append('ëª¨ì…˜')\n",
    "    elif arr3[i]==22:\n",
    "        category3.append('ë°°ê²½')\n",
    "    elif arr3[i]==23:\n",
    "        category3.append('ê·¸ë˜í”½')\n",
    "    elif arr3[i]==24:\n",
    "        category3.append('ì†Œë¦¬')\n",
    "    elif arr3[i]==25:\n",
    "        category3.append('ë””ìì¸')\n",
    "    elif arr3[i]==26:\n",
    "        category3.append('ìºë¦­í„°')\n",
    "    elif arr3[i]==27:\n",
    "        category3.append('ìŠ¤í‚¬')\n",
    "    elif arr3[i]==28:\n",
    "        category3.append('ì˜ì›…')\n",
    "    elif arr3[i]==29:\n",
    "        category3.append('ì•„ì´í…œ')\n",
    "    elif arr3[i]==30:\n",
    "        category3.append('ìŠ¤í‚¨')\n",
    "    elif arr3[i]==31:\n",
    "        category3.append('ì—…ë°ì´íŠ¸')\n",
    "    elif arr3[i]==32:\n",
    "        category3.append('ìš©ëŸ‰')\n",
    "    elif arr3[i]==33:\n",
    "        category3.append('ë‹¤ìš´')\n",
    "    elif arr3[i]==34:\n",
    "        category3.append('ë²„ê·¸')\n",
    "    elif arr3[i]==35:\n",
    "        category3.append('ì„¤ì¹˜')\n",
    "    elif arr3[i]==50:\n",
    "        category3.append('ê¸°íƒ€')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = Counter(category1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "count2 = Counter(category2)\n",
    "count3 = Counter(category3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_category = pd.DataFrame({'writer':train_reviews['writer'], 'content':train_reviews['content'], 'category1':category1, 'category2':category2, 'category3':category3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter1 = save_category['category1'] == 'ë‚œì´ë„'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>writer</th>\n",
       "      <th>content</th>\n",
       "      <th>category1</th>\n",
       "      <th>category2</th>\n",
       "      <th>category3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ë°•ê¸°ë‚¨</td>\n",
       "      <td>ì‰¬ìš´ê²ƒë„ ì•„ë‹ˆê³  ê·¸ë ‡ë‹¤ê³  ë„ˆë¬´ ì–´ë ¤ìš´ê²ƒë„ ì•„ë‹ˆì—¬ì„œ ì§‘ì¤‘ì´ ì˜ ë¼ìš”</td>\n",
       "      <td>ë‚œì´ë„</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>ìµœë¬¸ì •</td>\n",
       "      <td>ì•„ìŠ¬ì•„ìŠ¬ í•œê²Œ ì¬ë¯¸ìˆëŠ”ë° ìš” ì–´ë ¤ìš´ ê²ƒì¡°ì°¨ ì•„ë‹ˆê³ ìš”</td>\n",
       "      <td>ë‚œì´ë„</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3524</th>\n",
       "      <td>í—¬ë¡œìœ ë‹ˆë¦¬ë‹ˆì€ì„œ</td>\n",
       "      <td>ì¢€ì–´ë ¤ìš´ë°í• ë§Œí•´ìš”!</td>\n",
       "      <td>ë‚œì´ë„</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4067</th>\n",
       "      <td>ì •ì„ </td>\n",
       "      <td>ë„ˆë¬´ ì–´ë ¤ìš´ë° ì¬ë¯¸ìˆì–´ë‡¨</td>\n",
       "      <td>ë‚œì´ë„</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5205</th>\n",
       "      <td>ê¹€ë„ì—°</td>\n",
       "      <td>ì–´ë ¤ìš´ê±´ ì–´ë µê³  ì‰¬ìš´ê±´ ì‰½ê³ &gt;&lt; ë‹¨ì§ ë‹¨ì§ ì´ ì˜ ì´ë£¨ì–´ì ¸ ìˆì–´ìš©!!ğŸ‘ğŸ‘ 5ê°œ ë˜ë©´ ë§Œ...</td>\n",
       "      <td>ë‚œì´ë„</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235099</th>\n",
       "      <td>í˜œì›</td>\n",
       "      <td>ì–´ë ¤ìš´ë° ì¬ë¯¸ì—ˆìš”</td>\n",
       "      <td>ë‚œì´ë„</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235849</th>\n",
       "      <td>ë°±kissso5208</td>\n",
       "      <td>ë ˆë²¨ì—…ì€ ì–´ë ¤ìš´ê²Œ ì—†ëŠ”ë° ì½”ì¸ì´ë‚˜ ì°½ê³ ë‚˜ ê±´ì„¤ì™„ë£Œì‹œ ì¬ë£Œ ì–»ê¸°ë‚˜ ì¢€ ì–´ë ¤ì›Œ ì™„ê³µì´ ...</td>\n",
       "      <td>ë‚œì´ë„</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236205</th>\n",
       "      <td>ë³´ê²½ê¹€</td>\n",
       "      <td>ì´ ê²Œì„ì€ ì–´ë ¤ìš´ í¼ì¦ì„ ë§ìš°ëŠ” ê¸°ë¶„ì´ì—ìš”!</td>\n",
       "      <td>ë‚œì´ë„</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236647</th>\n",
       "      <td>ë¬¸ê²½ë³µ</td>\n",
       "      <td>ê²Œì„ì€ ì¬ë¯¸ìˆê¸°ëŠ” í•˜ë‚˜ ë§Œë“¤ê¸°ê°€ ë„ˆë¬´ ì–´ë ¤ìš´ë“¯í•˜ë„¤ìš”</td>\n",
       "      <td>ë‚œì´ë„</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237158</th>\n",
       "      <td>ì´ì§€ìˆ™</td>\n",
       "      <td>ì‹œì‘í•œ ì§€ ì–¼ë§ˆ ì•ˆë˜ì„œ ì–´ë ¤ìš´ ì ì€ ì˜ ëª» ëŠë¼ì§€ë§Œ ì•„ë¬´ë˜ë„ ì—…ê·¸ë ˆì´ë“œí•  ë•Œ í•„ìš”í•œ...</td>\n",
       "      <td>ë‚œì´ë„</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>689 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             writer                                            content  \\\n",
       "38              ë°•ê¸°ë‚¨               ì‰¬ìš´ê²ƒë„ ì•„ë‹ˆê³  ê·¸ë ‡ë‹¤ê³  ë„ˆë¬´ ì–´ë ¤ìš´ê²ƒë„ ì•„ë‹ˆì—¬ì„œ ì§‘ì¤‘ì´ ì˜ ë¼ìš”   \n",
       "2474            ìµœë¬¸ì •                       ì•„ìŠ¬ì•„ìŠ¬ í•œê²Œ ì¬ë¯¸ìˆëŠ”ë° ìš” ì–´ë ¤ìš´ ê²ƒì¡°ì°¨ ì•„ë‹ˆê³ ìš”   \n",
       "3524       í—¬ë¡œìœ ë‹ˆë¦¬ë‹ˆì€ì„œ                                         ì¢€ì–´ë ¤ìš´ë°í• ë§Œí•´ìš”!   \n",
       "4067             ì •ì„                                       ë„ˆë¬´ ì–´ë ¤ìš´ë° ì¬ë¯¸ìˆì–´ë‡¨   \n",
       "5205            ê¹€ë„ì—°  ì–´ë ¤ìš´ê±´ ì–´ë µê³  ì‰¬ìš´ê±´ ì‰½ê³ >< ë‹¨ì§ ë‹¨ì§ ì´ ì˜ ì´ë£¨ì–´ì ¸ ìˆì–´ìš©!!ğŸ‘ğŸ‘ 5ê°œ ë˜ë©´ ë§Œ...   \n",
       "...             ...                                                ...   \n",
       "235099           í˜œì›                                          ì–´ë ¤ìš´ë° ì¬ë¯¸ì—ˆìš”   \n",
       "235849  ë°±kissso5208  ë ˆë²¨ì—…ì€ ì–´ë ¤ìš´ê²Œ ì—†ëŠ”ë° ì½”ì¸ì´ë‚˜ ì°½ê³ ë‚˜ ê±´ì„¤ì™„ë£Œì‹œ ì¬ë£Œ ì–»ê¸°ë‚˜ ì¢€ ì–´ë ¤ì›Œ ì™„ê³µì´ ...   \n",
       "236205          ë³´ê²½ê¹€                           ì´ ê²Œì„ì€ ì–´ë ¤ìš´ í¼ì¦ì„ ë§ìš°ëŠ” ê¸°ë¶„ì´ì—ìš”!   \n",
       "236647          ë¬¸ê²½ë³µ                       ê²Œì„ì€ ì¬ë¯¸ìˆê¸°ëŠ” í•˜ë‚˜ ë§Œë“¤ê¸°ê°€ ë„ˆë¬´ ì–´ë ¤ìš´ë“¯í•˜ë„¤ìš”   \n",
       "237158          ì´ì§€ìˆ™  ì‹œì‘í•œ ì§€ ì–¼ë§ˆ ì•ˆë˜ì„œ ì–´ë ¤ìš´ ì ì€ ì˜ ëª» ëŠë¼ì§€ë§Œ ì•„ë¬´ë˜ë„ ì—…ê·¸ë ˆì´ë“œí•  ë•Œ í•„ìš”í•œ...   \n",
       "\n",
       "       category1 category2 category3  \n",
       "38           ë‚œì´ë„        ê¸°íƒ€        ê¸°íƒ€  \n",
       "2474         ë‚œì´ë„        ê¸°íƒ€        ê¸°íƒ€  \n",
       "3524         ë‚œì´ë„        ê¸°íƒ€        ê¸°íƒ€  \n",
       "4067         ë‚œì´ë„        ê¸°íƒ€        ê¸°íƒ€  \n",
       "5205         ë‚œì´ë„        ê¸°íƒ€        ê¸°íƒ€  \n",
       "...          ...       ...       ...  \n",
       "235099       ë‚œì´ë„        ê¸°íƒ€        ê¸°íƒ€  \n",
       "235849       ë‚œì´ë„        ê¸°íƒ€        ê¸°íƒ€  \n",
       "236205       ë‚œì´ë„        ê¸°íƒ€        ê¸°íƒ€  \n",
       "236647       ë‚œì´ë„        ê¸°íƒ€        ê¸°íƒ€  \n",
       "237158       ë‚œì´ë„        ê¸°íƒ€        ê¸°íƒ€  \n",
       "\n",
       "[689 rows x 5 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_category[filter1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>writer</th>\n",
       "      <th>content</th>\n",
       "      <th>category1</th>\n",
       "      <th>category2</th>\n",
       "      <th>category3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ì „ë¯¸ë¦¼</td>\n",
       "      <td>ê´‘ê³ ê°€ë„ˆë¬´ë§ì´ë‚˜ì˜¤ê³  ë„ˆë¬´ì§œì¦ë‚˜ìš”ê·¸ë¦¬ê³ ë§Œë“ ë¶„ë“¤ê¹¨ëŠ”ì œì†¡í•˜ì§€ë§Œ ê·¸ë ˆë„ ê´‘êµ¬ëŠ”ë„ˆë¬´ë§ì´ë‚˜ì™€ì—¬...</td>\n",
       "      <td>ê´‘ê³ </td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ì–‘í˜œìš´</td>\n",
       "      <td>í¼ì¦ê²Œì„ë¥¸ ì¢‹ìœ¼ë‚˜ í¼ì¦ì»¨íŠ¸ë¡¤ì„ ë„ˆë¬´ ë©‹ëŒ€ë¡œ ëˆëŠ”ë‹¤ì˜¹~~ ì´ë™ë¶ˆê°€ë¡œëˆëŠ”ê²ƒë³´ë‹¤ í¼ì¦ì´ê½‰...</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ë°•ì¬í˜„</td>\n",
       "      <td>ë‘ë‡Œë¥¼ ë§ì´ ì“°ê²Œ ë˜ëŠ” ê²Œì„ì´ê³ , ì¬ë¯¸ ë˜í•œ ë›°ì–´ë‚˜ì„œ í•œë²ˆì‹œì‘í•˜ë©´ ì†ì„ ë†“ì§€ ëª»í•˜ëŠ”...</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ê¶Œì†Œì› ë˜¥ê°œ</td>\n",
       "      <td>ì§„ì§œ ì¢‹ì•„ìš” ë‹¤ë¥¸ ì´ëŸ° ê²Œì„ í• ë–¼ëŠ” ì˜ ì•ˆëê±°ë“ ìš”??? ê·¼ë° ì´ê±¸ í•˜ë©´ 900ì€ ê¸ˆ...</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alice Han</td>\n",
       "      <td>ì‹œê°„ ì œí•œë„ ì—†ê³  ê´‘ê³ ë„ ê³¼í•˜ì§€ ì•Šê³  ì¡°ì•„ìš” ì˜ ë§Œë“œì…¨ì–´ìš” ì •ì ì¸ ì„±í–¥ì˜ ì‚¬ëŒë“¤ì—ê²Œ...</td>\n",
       "      <td>ê´‘ê³ </td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238338</th>\n",
       "      <td>ì´ë™ì¤€</td>\n",
       "      <td>ë³„ ë°˜ìª½ ì£¼ê³  ì‹¶ì€ë° ì•ˆë˜ë„¤ ê·¸ë¦¬ê³  í…”ë³´ ë²„ê·¸ í˜ì¹˜ ì¢€</td>\n",
       "      <td>ë²„ê·¸</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238339</th>\n",
       "      <td>ê¹€ë ˆì„œ</td>\n",
       "      <td>ë ‰ ì¡°ì§€ê²Œ ê±¸ë¦¬ê³  ì‹¤í–‰ë„ ì•ˆ ë¼</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238340</th>\n",
       "      <td>prion choi</td>\n",
       "      <td>ë§¤ë²ˆ ê´‘ê³ </td>\n",
       "      <td>ê´‘ê³ </td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238341</th>\n",
       "      <td>ê¹€YT</td>\n",
       "      <td>ë…¸ì¼</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238342</th>\n",
       "      <td>ì˜¤íƒœí™˜</td>\n",
       "      <td>ì˜¤ì„¸ë¯¼</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "      <td>ê¸°íƒ€</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238343 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            writer                                            content  \\\n",
       "0              ì „ë¯¸ë¦¼  ê´‘ê³ ê°€ë„ˆë¬´ë§ì´ë‚˜ì˜¤ê³  ë„ˆë¬´ì§œì¦ë‚˜ìš”ê·¸ë¦¬ê³ ë§Œë“ ë¶„ë“¤ê¹¨ëŠ”ì œì†¡í•˜ì§€ë§Œ ê·¸ë ˆë„ ê´‘êµ¬ëŠ”ë„ˆë¬´ë§ì´ë‚˜ì™€ì—¬...   \n",
       "1              ì–‘í˜œìš´  í¼ì¦ê²Œì„ë¥¸ ì¢‹ìœ¼ë‚˜ í¼ì¦ì»¨íŠ¸ë¡¤ì„ ë„ˆë¬´ ë©‹ëŒ€ë¡œ ëˆëŠ”ë‹¤ì˜¹~~ ì´ë™ë¶ˆê°€ë¡œëˆëŠ”ê²ƒë³´ë‹¤ í¼ì¦ì´ê½‰...   \n",
       "2              ë°•ì¬í˜„  ë‘ë‡Œë¥¼ ë§ì´ ì“°ê²Œ ë˜ëŠ” ê²Œì„ì´ê³ , ì¬ë¯¸ ë˜í•œ ë›°ì–´ë‚˜ì„œ í•œë²ˆì‹œì‘í•˜ë©´ ì†ì„ ë†“ì§€ ëª»í•˜ëŠ”...   \n",
       "3           ê¶Œì†Œì› ë˜¥ê°œ  ì§„ì§œ ì¢‹ì•„ìš” ë‹¤ë¥¸ ì´ëŸ° ê²Œì„ í• ë–¼ëŠ” ì˜ ì•ˆëê±°ë“ ìš”??? ê·¼ë° ì´ê±¸ í•˜ë©´ 900ì€ ê¸ˆ...   \n",
       "4        Alice Han  ì‹œê°„ ì œí•œë„ ì—†ê³  ê´‘ê³ ë„ ê³¼í•˜ì§€ ì•Šê³  ì¡°ì•„ìš” ì˜ ë§Œë“œì…¨ì–´ìš” ì •ì ì¸ ì„±í–¥ì˜ ì‚¬ëŒë“¤ì—ê²Œ...   \n",
       "...            ...                                                ...   \n",
       "238338         ì´ë™ì¤€                     ë³„ ë°˜ìª½ ì£¼ê³  ì‹¶ì€ë° ì•ˆë˜ë„¤ ê·¸ë¦¬ê³  í…”ë³´ ë²„ê·¸ í˜ì¹˜ ì¢€   \n",
       "238339         ê¹€ë ˆì„œ                                  ë ‰ ì¡°ì§€ê²Œ ê±¸ë¦¬ê³  ì‹¤í–‰ë„ ì•ˆ ë¼   \n",
       "238340  prion choi                                              ë§¤ë²ˆ ê´‘ê³    \n",
       "238341         ê¹€YT                                                 ë…¸ì¼   \n",
       "238342         ì˜¤íƒœí™˜                                                ì˜¤ì„¸ë¯¼   \n",
       "\n",
       "       category1 category2 category3  \n",
       "0             ê´‘ê³         ê¸°íƒ€        ê¸°íƒ€  \n",
       "1             ê¸°íƒ€        ê¸°íƒ€        ê¸°íƒ€  \n",
       "2             ê¸°íƒ€        ê¸°íƒ€        ê¸°íƒ€  \n",
       "3             ê¸°íƒ€        ê¸°íƒ€        ê¸°íƒ€  \n",
       "4             ê´‘ê³         ê¸°íƒ€        ê¸°íƒ€  \n",
       "...          ...       ...       ...  \n",
       "238338        ë²„ê·¸        ê¸°íƒ€        ê¸°íƒ€  \n",
       "238339        ê¸°íƒ€        ê¸°íƒ€        ê¸°íƒ€  \n",
       "238340        ê´‘ê³         ê¸°íƒ€        ê¸°íƒ€  \n",
       "238341        ê¸°íƒ€        ê¸°íƒ€        ê¸°íƒ€  \n",
       "238342        ê¸°íƒ€        ê¸°íƒ€        ê¸°íƒ€  \n",
       "\n",
       "[238343 rows x 5 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'ê¸°íƒ€': 142696, 'ê´‘ê³ ': 39296, 'ì—…ë°ì´íŠ¸': 6224, 'ë²„ê·¸': 6048, 'í˜„ì§ˆ': 5893, 'ìºë¦­í„°': 5175, 'ì•„ì´í…œ': 4465, 'ê·¸ë˜í”½': 3082, 'ì´ë²¤íŠ¸': 2319, 'ì ‘ì†': 2120, 'ì„¤ì¹˜': 2069, 'ë„¤íŠ¸ì›Œí¬': 1761, 'ê³„ì •': 1546, 'ì„œë²„': 1367, 'ê²°ì œ': 1321, 'ì†Œë¦¬': 1166, 'ìŠ¤í…Œì´ì§€': 1152, 'ë¡œë”©': 946, 'ë‹¤ìš´': 937, 'êµ¬ë§¤': 916, 'ë¡œê·¸ì¸': 908, 'ìŠ¤í‚¨': 808, 'ì—°ê²°': 741, 'ìŠ¤í‚¬': 725, 'ë‚œì´ë„': 689, 'ì˜ì›…': 568, 'í™˜ë¶ˆ': 551, 'í€˜ìŠ¤íŠ¸': 469, 'ì¶©ì „': 370, 'ë””ìì¸': 350, 'ê°€ì…': 344, 'ë°°ê²½': 332, 'ì—°ë™': 276, 'êµ¬ì„±': 239, 'ìš©ëŸ‰': 190, 'ì•„ì´ë””': 159, 'ëª¨ì…˜': 125})\n"
     ]
    }
   ],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'ê¸°íƒ€': 210404, 'ì•„ì´í…œ': 3299, 'ìºë¦­í„°': 2498, 'ë„¤íŠ¸ì›Œí¬': 1859, 'í˜„ì§ˆ': 1792, 'ê´‘ê³ ': 1485, 'ë²„ê·¸': 1442, 'ìŠ¤í…Œì´ì§€': 1153, 'ê²°ì œ': 1120, 'ì—…ë°ì´íŠ¸': 903, 'ê³„ì •': 868, 'ì´ë²¤íŠ¸': 857, 'ì„œë²„': 807, 'í™˜ë¶ˆ': 795, 'ì„¤ì¹˜': 729, 'êµ¬ë§¤': 724, 'ë‹¤ìš´': 720, 'ì ‘ì†': 682, 'ê·¸ë˜í”½': 661, 'ì—°ê²°': 651, 'ë¡œê·¸ì¸': 556, 'ì†Œë¦¬': 544, 'ë¡œë”©': 533, 'ìŠ¤í‚¨': 443, 'ìŠ¤í‚¬': 410, 'ì—°ë™': 405, 'ì˜ì›…': 291, 'ë‚œì´ë„': 226, 'í€˜ìŠ¤íŠ¸': 221, 'ì¶©ì „': 204, 'ì•„ì´ë””': 196, 'ìš©ëŸ‰': 182, 'ë””ìì¸': 177, 'ë°°ê²½': 153, 'ê°€ì…': 136, 'ëª¨ì…˜': 118, 'êµ¬ì„±': 99})\n"
     ]
    }
   ],
   "source": [
    "print(count2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'ê¸°íƒ€': 227439, 'ì•„ì´í…œ': 2583, 'ì´ë²¤íŠ¸': 1235, 'ìºë¦­í„°': 917, 'ë²„ê·¸': 591, 'í˜„ì§ˆ': 456, 'ë„¤íŠ¸ì›Œí¬': 424, 'í™˜ë¶ˆ': 406, 'ì—…ë°ì´íŠ¸': 401, 'ê³„ì •': 335, 'ê²°ì œ': 303, 'ìŠ¤í…Œì´ì§€': 289, 'ì„œë²„': 284, 'ì—°ê²°': 242, 'ê´‘ê³ ': 221, 'ë¡œê·¸ì¸': 198, 'êµ¬ë§¤': 184, 'ì ‘ì†': 175, 'ì—°ë™': 163, 'ì„¤ì¹˜': 157, 'ë¡œë”©': 151, 'ê·¸ë˜í”½': 140, 'ìŠ¤í‚¬': 115, 'ë‹¤ìš´': 109, 'ìŠ¤í‚¨': 105, 'ì†Œë¦¬': 92, 'ì¶©ì „': 74, 'ì•„ì´ë””': 68, 'ì˜ì›…': 66, 'í€˜ìŠ¤íŠ¸': 64, 'ë‚œì´ë„': 59, 'ëª¨ì…˜': 58, 'ìš©ëŸ‰': 57, 'ê°€ì…': 56, 'ë°°ê²½': 46, 'ë””ìì¸': 43, 'êµ¬ì„±': 37})\n"
     ]
    }
   ],
   "source": [
    "print(count3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'ê¸°íƒ€': 580539, 'ê´‘ê³ ': 41002, 'ì•„ì´í…œ': 10347, 'ìºë¦­í„°': 8590, 'í˜„ì§ˆ': 8141, 'ë²„ê·¸': 8081, 'ì—…ë°ì´íŠ¸': 7528, 'ì´ë²¤íŠ¸': 4411, 'ë„¤íŠ¸ì›Œí¬': 4044, 'ê·¸ë˜í”½': 3883, 'ì ‘ì†': 2977, 'ì„¤ì¹˜': 2955, 'ê³„ì •': 2749, 'ê²°ì œ': 2744, 'ìŠ¤í…Œì´ì§€': 2594, 'ì„œë²„': 2458, 'êµ¬ë§¤': 1824, 'ì†Œë¦¬': 1802, 'ë‹¤ìš´': 1766, 'í™˜ë¶ˆ': 1752, 'ë¡œê·¸ì¸': 1662, 'ì—°ê²°': 1634, 'ë¡œë”©': 1630, 'ìŠ¤í‚¨': 1356, 'ìŠ¤í‚¬': 1250, 'ë‚œì´ë„': 974, 'ì˜ì›…': 925, 'ì—°ë™': 844, 'í€˜ìŠ¤íŠ¸': 754, 'ì¶©ì „': 648, 'ë””ìì¸': 570, 'ê°€ì…': 536, 'ë°°ê²½': 531, 'ìš©ëŸ‰': 429, 'ì•„ì´ë””': 423, 'êµ¬ì„±': 375, 'ëª¨ì…˜': 301})\n"
     ]
    }
   ],
   "source": [
    "print(count + count2 + count3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_category.to_csv('./review/{}_{}_reviews.csv'.format(i, game_title), sep=',', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "pymysql.install_as_MySQLdb()\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (1366, \"Incorrect string value: '\\\\xB4\\\\xEB\\\\xC7\\\\xD1\\\\xB9\\\\xCE...' for column 'VARIABLE_VALUE' at row 1\")\n",
      "  result = self._query(query)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# MySQL Connector using pymysql\n",
    "pymysql.install_as_MySQLdb()\n",
    "import MySQLdb\n",
    "\n",
    "engine = create_engine(\"mysql+mysqldb://root:\"+\"0000\"+\"@localhost:3306/capstone\", encoding='utf-8')\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#from konlpy.tag import Mecab\n",
    "import MeCab\n",
    "from konlpy.tag import Okt\n",
    "import re\n",
    "import nltk\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "\n",
    "import string\n",
    "mecab = MeCab.Tagger()\n",
    "from tqdm import tqdm_notebook\n",
    "import json\n",
    "import os\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_reviews = pd.read_csv('C:/capstone/review/16200_ROBLOX_reviews.csv', usecols =[\"content\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_content = emo_reviews['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    with open(filename, 'r' , encoding=\"utf-8\") as f:\n",
    "        data = [line.split('\\t') for line in f.read().splitlines()]\n",
    "        data = data[1:]\n",
    "    return data\n",
    "\n",
    "train_data = read_data('C:/capstone/data/nsmc-master/ratings_train.txt')\n",
    "test_data = read_data('C:/capstone/data/nsmc-master/ratings_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "import json\n",
    "import os\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    # normì€ ì •ê·œí™”, stemì€ ê·¼ì–´ë¡œ í‘œì‹œí•˜ê¸°ë¥¼ ë‚˜íƒ€ëƒ„\n",
    "    return ['/'.join(t) for t in okt.pos(doc, norm=True, stem=True)]\n",
    "\n",
    "if os.path.isfile('train_docs.json'):\n",
    "    with open('train_docs.json', 'r', encoding=\"utf-8\") as f:\n",
    "        train_docs = json.load(f)\n",
    "    with open('test_docs.json', 'r', encoding=\"utf-8\") as f:\n",
    "        test_docs = json.load(f)\n",
    "else:\n",
    "    train_docs = [(tokenize(row[1]), row[2]) for row in train_data]\n",
    "    test_docs = [(tokenize(row[1]), row[2]) for row in test_data]\n",
    "    # JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "    with open('train_docs.json', 'rt', encoding=\"utf-8\") as make_file:\n",
    "        json.dump(train_docs, make_file, ensure_ascii=False, indent=\"\\t\")\n",
    "    with open('test_docs.json', 'rt', encoding=\"utf-8\") as make_file:\n",
    "        json.dump(test_docs, make_file, ensure_ascii=False, indent=\"\\t\")\n",
    "\n",
    "\n",
    "pprint(train_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [t for d in train_docs for t in d[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.Text(tokens, name='NMSC')\n",
    "\n",
    "# ì „ì²´ í† í°ì˜ ê°œìˆ˜\n",
    "print(len(text.tokens))\n",
    "\n",
    "# ì¤‘ë³µì„ ì œì™¸í•œ í† í°ì˜ ê°œìˆ˜\n",
    "print(len(set(text.tokens)))            \n",
    "\n",
    "# ì¶œí˜„ ë¹ˆë„ê°€ ë†’ì€ ìƒìœ„ í† í° 10ê°œ\n",
    "pprint(text.vocab().most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_words = [f[0] for f in text.vocab().most_common(1000)]\n",
    "\n",
    "def term_frequency(doc):\n",
    "    return [doc.count(word) for word in selected_words]\n",
    "\n",
    "train_x = [term_frequency(d) for d, _ in train_docs]\n",
    "test_x = [term_frequency(d) for d, _ in test_docs]\n",
    "train_y = [c for _, c in train_docs]\n",
    "test_y = [c for _, c in test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray(train_x).astype('float32')\n",
    "x_test = np.asarray(test_x).astype('float32')\n",
    "\n",
    "y_train = np.asarray(train_y).astype('float32')\n",
    "y_test = np.asarray(test_y).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(1000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "             loss=losses.binary_crossentropy,\n",
    "             metrics=[metrics.binary_accuracy])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pos_neg(review):\n",
    "    token = tokenize(review)\n",
    "    tf = term_frequency(token)\n",
    "    data = np.expand_dims(np.asarray(tf).astype('float32'), axis=0)\n",
    "    score = float(model.predict(data))\n",
    "    if(score > 0.75):\n",
    "        emotion = 'ê¸ì •'\n",
    "        return emotion\n",
    "        #print(\"[{}]ëŠ” ë§Œì¡± ë¦¬ë·°ì…ë‹ˆë‹¤.^^\\n\".format(review))\n",
    "    elif(score > 0.5):\n",
    "        emotion = 'ì•½í•œ ê¸ì •'\n",
    "        return emotion\n",
    "        #print(\"[{}]ëŠ” ì•½ê°„ ë§Œì¡± ë¦¬ë·°ì…ë‹ˆë‹¤.^^\\n\".format(review))\n",
    "    elif(score>0.25):\n",
    "        #print(\"[{}]ëŠ” ì•½ê°„ ë¶ˆë§Œì¡± ë¦¬ë·°ì…ë‹ˆë‹¤.^^\\n\".format(review))\n",
    "        emotion = 'ì•½í•œ ë¶€ì •'\n",
    "        return emotion\n",
    "    else:\n",
    "        #print(\"[{}]ëŠ” ë¶ˆë§Œì¡± ë¦¬ë·°ì…ë‹ˆë‹¤.^^\\n\".format(review))\n",
    "        emotion = 'ë¶€ì •'\n",
    "        return emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_arr = list()\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    emo_arr.append(predict_pos_neg(r_content[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_category = pd.DataFrame({'writer':train_reviews['writer'], 'content':train_reviews['content'], 'category1':category1, 'category2':categort2, 'category3':category3, 'emotion':emo_arr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>writer</th>\n",
       "      <th>content</th>\n",
       "      <th>category1</th>\n",
       "      <th>category2</th>\n",
       "      <th>category3</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[yuna]ìœ ë‚˜</td>\n",
       "      <td>ê²Œì„ì€ ì¬ë°Œì§€ë§Œ ê´‘ê³ ê°€ ë§ì€ê±´ ì‚¬ì‹¤ì´ì˜ˆìš” í•˜ì§€ë§Œ ì—¬ëŸ¬ë¶„ ì´ëŸ° ê²Œì„ì€ ê´‘ê³ ê°€ ìˆì–´ì•¼ ...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>ì•½í•œ ë¶€ì •</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ì´ìˆœí™”</td>\n",
       "      <td>ì•„ë‹ˆ ì´ ê²Œì„ì„ ë„ˆë¬´ ì˜ ë§Œë“¤ì—ˆëŠ”ë° ê´‘ê³ ê°€ ë„ˆë¬´ ë§ì´ ë‚˜ì™€ìš”. í•œíŒí•˜ê³  ê´‘ê³ ê°€ ë‚˜ì˜¤...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>ì•½í•œ ë¶€ì •</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ë§ˆí¬TV ìƒŒì¦ˆ ë„í‹° ì ëœ° DJ ì—”ë”ë§¨</td>\n",
       "      <td>ê·¸ë ˆí”½,ì¬ë¯¸,í¥ë¯¸ ëª¨ë‘ ì¢‹ì•„ìš” ì»¨íŠ¸ë¡¤ë„ ë¶€ë“œëŸ½ê³  í•˜ì§€ë§Œ ì¢€ ë¶ˆí¸í•œê²Œ...ì¢€ ëˆê²¨ìš” ...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>ê¸ì •</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mp3</td>\n",
       "      <td>ì¬ë°Œê¸´ í•œë° ë‹¤ìŒ ìŠ¤í…Œì´ì§€ë¡œ ë„˜ì–´ê°€ëŠ” ì†ë„ê°€ ë„ˆë¬´ ëŠë¦¬ë‹¤. ê´‘ê³ ê°€ ë§ê¸´ í•œë° ì›ë˜ ...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>ì•½í•œ ë¶€ì •</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ê¹€ìˆ˜ê²½</td>\n",
       "      <td>ê²Œì„ì€ ì œë¯¸ìˆëŠ”ë° í•œíŒí•˜ë©´ ê´‘ê³ ë‚˜ì˜¤ê³  ë˜ í•œíŒí•˜ë©´ ê´‘ê³ ë‚˜ì˜¤ê³  ì´ê²Œë­¡ë‹ˆê¹Œ! ì´ì   ê´‘ê³ ...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>ì•½í•œ ê¸ì •</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>ì´íƒœì˜</td>\n",
       "      <td>ì¬ë¯¸ìˆì–´ìš”</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>ê¸ì •</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>Ohohh Jck</td>\n",
       "      <td>ì¡°ì•„ìš”</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>ê¸ì •</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>ì´í˜„ì„±í˜„ì„±</td>\n",
       "      <td>ì¬ë°‹ë‹¤</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>ê¸ì •</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>Sun Young Ah</td>\n",
       "      <td>ìµœê³ </td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>ê¸ì •</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>ì˜¤ì‹œí˜„</td>\n",
       "      <td>ê°œê°€ ì´ ê²Œì„ë³´ë‹¤ ë‚«ë‹¤. ì‹œê°„ë²„ë¦¬ëŠ” ê¼´ì´ë„¤ Dog is more great than...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>ë¶€ì •</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1800 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    writer                                            content  \\\n",
       "0                 [yuna]ìœ ë‚˜  ê²Œì„ì€ ì¬ë°Œì§€ë§Œ ê´‘ê³ ê°€ ë§ì€ê±´ ì‚¬ì‹¤ì´ì˜ˆìš” í•˜ì§€ë§Œ ì—¬ëŸ¬ë¶„ ì´ëŸ° ê²Œì„ì€ ê´‘ê³ ê°€ ìˆì–´ì•¼ ...   \n",
       "1                      ì´ìˆœí™”  ì•„ë‹ˆ ì´ ê²Œì„ì„ ë„ˆë¬´ ì˜ ë§Œë“¤ì—ˆëŠ”ë° ê´‘ê³ ê°€ ë„ˆë¬´ ë§ì´ ë‚˜ì™€ìš”. í•œíŒí•˜ê³  ê´‘ê³ ê°€ ë‚˜ì˜¤...   \n",
       "2     ë§ˆí¬TV ìƒŒì¦ˆ ë„í‹° ì ëœ° DJ ì—”ë”ë§¨  ê·¸ë ˆí”½,ì¬ë¯¸,í¥ë¯¸ ëª¨ë‘ ì¢‹ì•„ìš” ì»¨íŠ¸ë¡¤ë„ ë¶€ë“œëŸ½ê³  í•˜ì§€ë§Œ ì¢€ ë¶ˆí¸í•œê²Œ...ì¢€ ëˆê²¨ìš” ...   \n",
       "3                      mp3  ì¬ë°Œê¸´ í•œë° ë‹¤ìŒ ìŠ¤í…Œì´ì§€ë¡œ ë„˜ì–´ê°€ëŠ” ì†ë„ê°€ ë„ˆë¬´ ëŠë¦¬ë‹¤. ê´‘ê³ ê°€ ë§ê¸´ í•œë° ì›ë˜ ...   \n",
       "4                      ê¹€ìˆ˜ê²½  ê²Œì„ì€ ì œë¯¸ìˆëŠ”ë° í•œíŒí•˜ë©´ ê´‘ê³ ë‚˜ì˜¤ê³  ë˜ í•œíŒí•˜ë©´ ê´‘ê³ ë‚˜ì˜¤ê³  ì´ê²Œë­¡ë‹ˆê¹Œ! ì´ì   ê´‘ê³ ...   \n",
       "...                    ...                                                ...   \n",
       "1795                   ì´íƒœì˜                                              ì¬ë¯¸ìˆì–´ìš”   \n",
       "1796             Ohohh Jck                                                ì¡°ì•„ìš”   \n",
       "1797                 ì´í˜„ì„±í˜„ì„±                                                ì¬ë°‹ë‹¤   \n",
       "1798          Sun Young Ah                                                 ìµœê³    \n",
       "1799                   ì˜¤ì‹œí˜„  ê°œê°€ ì´ ê²Œì„ë³´ë‹¤ ë‚«ë‹¤. ì‹œê°„ë²„ë¦¬ëŠ” ê¼´ì´ë„¤ Dog is more great than...   \n",
       "\n",
       "      category1  category2  category3 emotion  \n",
       "0          34.0       50.0       50.0   ì•½í•œ ë¶€ì •  \n",
       "1          34.0       50.0       50.0   ì•½í•œ ë¶€ì •  \n",
       "2          50.0       50.0       50.0      ê¸ì •  \n",
       "3          34.0       18.0       50.0   ì•½í•œ ë¶€ì •  \n",
       "4          34.0       50.0       50.0   ì•½í•œ ê¸ì •  \n",
       "...         ...        ...        ...     ...  \n",
       "1795       50.0       50.0       50.0      ê¸ì •  \n",
       "1796       50.0       50.0       50.0      ê¸ì •  \n",
       "1797       50.0       50.0       50.0      ê¸ì •  \n",
       "1798       50.0       50.0       50.0      ê¸ì •  \n",
       "1799       50.0       50.0       50.0      ë¶€ì •  \n",
       "\n",
       "[1800 rows x 6 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MySQLë¡œ ì €ì¥\n",
    "save_category.to_sql(name='reviews', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
